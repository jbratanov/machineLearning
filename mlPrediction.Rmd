---
title: "mlPrediction"
author: "jbratanov"
date: "Tuesday, June 21, 2016"
output: html_document
---
### Summary
The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

### Data
Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions:

 + __Class A__ - exactly according to the specification
 + __Class B__ - throwing the elbows to the front
 + __Class C__ - lifting the dumbbell only halfway
 + __Class D__ - lowering the dumbbell only halfway
 + __Class E__ - throwing the hips to the front

This data is assessed using the __"classe"__ variable in the training dataset


### Data Processing

```{r cache=TRUE}

 # load train data
 train_df <- read.csv("c:/coursera/machineLearning/project/pml-training.csv", colClasses="character", header= TRUE,
                    stringsAsFactors = FALSE)
 # load test data
 test_df <- read.csv("c:/coursera/machineLearning/project/pml-testing.csv", colClasses="character", header= TRUE,
                    stringsAsFactors = FALSE)     


```
#### Data Cleansing

*  Observe raw data through RStudio and determine columns not useful for prediction exercise
    + Will remove first 7 variables which are related to user, time, etc..
    + Was going to consider timestamp as an option thinking time of day may be an influence, but not enough time span
*  Validate variable programmically to see which ones are numeric
*  Validate to see which variables have enough useful data to use for prediction.  Using 95% as tolerance.

```{r}
# remove first 7 vars
train_df[1:7] <- list(NULL)
test_df[1:7] <- list(NULL)
##############################################
# Pre-process training data 
#remove columns which are NA, missing values
# or non-numeric using 95% tolerance
##############################################
tolerance <- nrow(train_df) * .05
colCnt <- ncol(train_df)-1
listCnt=1
badColList <- list()
# Loop and build list of columns which don't meet clean data criteria
# Remember not to change or delete "classe" variable
for (i in 1:colCnt)
  {
    if (colSums(is.na(train_df[i]))  > tolerance
       || sum(train_df[i] == "") > tolerance)
      {
        badColList[listCnt] <- colnames(train_df[i])
        listCnt <- listCnt + 1
      }
    else
      {
         # change columns we are keeping into numeric
         train_df[,i] <- as.numeric(as.character(train_df[,i]))
      }
  }
# Drop list of columns not used
train_df <- train_df[, !(names(train_df) %in% badColList)] 

##############################################
# Pre-process test data 
#remove columns which are NA, missing values
# or non-numeric using 95% tolerance
##############################################
tolerance <- nrow(test_df) * .05
colCnt <- ncol(test_df)-1
testlistCnt=1
testbadColList <- list()
# Loop and build list of columns which don't meet clean data criteria
# Remember not to change or delete "classe" variable
for (i in 1:colCnt)
  {
    if (colSums(is.na(test_df[i]))  > tolerance
       || sum(test_df[i] == "") > tolerance)
      {
        testbadColList[testlistCnt] <- colnames(test_df[i])
        testlistCnt <- testlistCnt + 1
      }
    else
      {
         # change columns we are keeping into numeric
         test_df[,i] <- as.numeric(as.character(test_df[,i]))
      }
  }
# Drop list of columns not used
test_df <- test_df[, !(names(test_df) %in% testbadColList)] 



```
#### Data to be used for prediction
After data cleaning, the following variables will be used.
```{r}
names(train_df)
names(test_df)
```
#### Prediction models
Set PCA to reduce the dimension of the data.  Get to the important stuff using cross-validation (cv) method
```{r cache=TRUE}
# Load packages required for prediction functionality
library(caret)
# Set seed to 1.  easy to remember
set.seed(1)
# Create training and cross-validation datasets
inTrain = createDataPartition(train_df$classe, p = 0.7, list=FALSE)
myTrain = train_df[inTrain,]
cvTrain = train_df[-inTrain,]

tcData <- trainControl(method = "cv", number = 5, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
# Using random forest (rf) method as offline pre-processing check validates good accuracy
myTrain_rf <- train(classe ~ ., data = myTrain, method = "rf", trControl=tcData)
```



### Contributions
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz4CECF4g6O
